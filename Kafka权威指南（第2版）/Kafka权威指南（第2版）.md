1. 初识Kafka

## 1.1　发布与订阅消息系统

数据（消息）的发送者（发布者）不会直接把消息发送给接收者，这是发布与订阅消息系统的一个特点。发布者以某种方式对消息进行分类，接收者（订阅者）通过订阅它们来接收特定类型的消息。发布与订阅系统一般会有一个broker，也就是发布消息的地方。

真正需要的是一个单一的集中式系统，它可以用来发布通用的数据，并且规模可以随着公司业务的增长而增长。

## 1.2　Kafka登场

Kafka就是为了解决上述问题而设计的一款基于发布与订阅模式的消息系统。

### 1.2.1　消息和批次

Kafka的数据单元被称为消息。消息可以有一个可选的元数据，也就是键。当需要以一种可控的方式将消息写入不同的分区时，需要用到键。最简单的例子就是为键生成一个一致性哈希值，然后用哈希值对主题分区数进行取模，为消息选取分区。这样可以保证具有相同键的消息总是会被写到相同的分区中（前提是分区数量没有发生变化）​。

为了提高效率，消息会被分成批次写入Kafka。批次包含了一组属于同一个主题和分区的消息。如果每一条消息都单独穿行于网络中，那么就会导致大量的网络开销，把消息分成批次传输可以减少网络开销。不过，这需要在时间延迟和吞吐量之间做出权衡：批次越大，单位时间内处理的消息就越多，对单条消息来说，其传输时间就越长。消息批次会被压缩，这样可以提升数据的传输和存储性能，但需要做更多的计算处理。

### 1.2.2　模式

### 1.2.3　主题和分区

Kafka的消息通过主题进行分类。主题就好比数据库的表或文件系统的文件夹。主题可以被分为若干个分区，一个分区就是一个提交日志。

需要注意的是，由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内是有序的。

![avatar](img/1.png)

生产者创建消息。在其他发布与订阅系统中，生产者可能被称为发布者或写入者。一条消息会被发布到一个特定的主题上。在默认情况下，生产者会把消息均衡地分布到主题的所有分区中。不过，在某些情况下，生产者会把消息直接写入指定的分区，这通常是通过消息键和分区器来实现的。分区器会为键生成一个哈希值，并将其映射到指定的分区，这样可以保证包含同一个键的消息被写入同一个分区。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到不同的分区。

消费者读取消息。在其他发布与订阅系统中，消费者可能被称为订阅者或读取者。消费者会订阅一个或多个主题，并按照消息写入分区的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量（不断递增的整数值）是另一种元数据，在创建消息时，Kafka会把它添加到消息里。在给定的分区中，每一条消息的偏移量都是唯一的，越往后消息的偏移量越大（但不一定是严格单调递增）​。消费者会把每一个分区可能的下一个偏移量保存起来（通常保存在Kafka中）​，如果消费者关闭或重启，则其读取状态不会丢失。

消费者可以是消费者群组的一部分，属于同一群组的一个或多个消费者共同读取一个主题。群组可以保证每个分区只被这个群组里的一个消费者读取

消费者与分区之间的映射通常被称为消费者对分区的所有权关系。

通过这种方式，消费者可以读取包含大量消息的主题。而且，如果一个消费者失效，那么群组里的其他消费者可以接管失效消费者的工作。

### 1.2.5　broker和集群

一台单独的Kafka服务器被称为broker。broker会接收来自生产者的消息，为其设置偏移量，并提交到磁盘保存。broker会为消费者提供服务，对读取分区的请求做出响应，并返回已经发布的消息。

broker组成了集群。每个集群都有一个同时充当了集群控制器角色的broker（自动从活动的集群成员中选举出来）​。控制器负责管理工作，包括为broker分配分区和监控broker。在集群中，一个分区从属于一个broker，这个broker被称为分区的首领。一个被分配给其他broker的分区副本（参见图1-7）叫作这个分区的“跟随者”​。分区复制提供了分区的消息冗余，如果一个broker发生故障，则其中的一个跟随者可以接管它的领导权。所有想要发布消息的生产者必须连接到首领，但消费者可以从首领或者跟随者那里读取消息。第7章将详细介绍如何操作集群（包括复制分区）​。

保留消息（在一定期限内）是Kafka的一个重要特性。broker默认的消息保留策略是这样的：要么保留一段时间（如7天）​，要么保留消息总量达到一定的字节数（如1 GB）​。当消息数量达到这些上限时，旧消息就会过期并被删除。

### 1.2.6　多集群

随着broker数量的增加，最好使用多个集群，原因如下。
● 数据类型分离
● 安全需求隔离
● 多数据中心（灾难恢复）

需要注意的是，Kafka的消息复制机制只能在单个集群中而不能在多个集群之间进行。

## 1.3　为什么选择Kafka

### 1.3.1　多个生产者

Kafka可以无缝支持多个生产者，不管客户端消费的是单个主题还是多个主题。所以，它很适用于从多个前端系统收集数据，并以统一的格式对外提供数据。

### 1.3.2　多个消费者

除了支持多个生产者，Kafka也支持多个消费者从一个单独的消息流读取数据，而且消费者之间互不影响。这与其他队列系统不同。在其他队列系统中，消息一旦被一个客户端读取，就无法再被其他客户端读取。多个消费者还可以组成一个群组，它们共享一个消息流，并保证整个群组只处理一次给定的消息。

### 1.3.3　基于磁盘的数据保留

Kafka不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于Kafka的数据保留特性。消息会被提交到磁盘，并根据设置的保留策略进行保存。每个主题可以设置单独的保留策略，以满足不同消费者的需求。各个主题还可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰而无法及时读取消息，在这种情况下，持久化的数据可以保证数据不会丢失

### 1.3.4　伸缩性

为了能够轻松地处理大量数据，Kafka从一开始就被设计成一个具备灵活伸缩性的系统。用户可以在开发阶段使用单个broker，然后再扩展到包含3个broker的小型开发集群。随着数据量不断增长，在部署到生产环境时，集群可以包含上百个broker。对在线集群进行扩展丝毫不影响系统的整体可用性。也就是说，一个包含多个broker的集群，即使个别broker失效，仍然可以持续地为客户端提供服务

### 1.3.5　高性能

### 1.3.6　平台特性

Kafka核心项目还加入了一些流式平台特性，从而使开发人员能够更容易执行一些常见的任务。结构化运行时环境）​，但这些特性会以API和开。

### 1.4　数据生态系统

应用场景：

- 活动跟踪
- 传递消息
- 指标和日志记录
- 提交日志
- 流式处理

# 第2章　安装Kafka

## 2.1　环境配置

### 2.1.1　选择操作系统

### 2.1.2　安装Java

在安装ZooKeeper或Kafka之前，需要有一个Java运行时环境。Kafka和ZooKeeper可以运行在所有基于OpenJDK的Java运行时中，包括OracleJDK。

### 2.1.3　安装ZooKeeper

为了保证高可用，ZooKeeper以集群（被称为群组）的方式运行。由于使用了再均衡算法，建议一个ZooKeeper集群应该包含奇数个节点（比如3个、5个等）​。只有当群组中的大多数节点（也就是所谓的仲裁）处于可用状态时，ZooKeeper才能处理外部请求。也就是说，一个包含3个节点的群组允许1个节点失效，而一个包含5个节点的群组允许2个节点失效。

## 2.2　安装broker

根据时间保留数据是通过检查日志片段文件的最后修改时间来实现的。一般来说，最后修改时间就是日志片段的关闭时间，也就是文件中最后一条消息的时间戳。不过，如果使用管理工具在服务器间移动分区，那么最后修改时间就不准确了，这种误差可能会导致这些分区过多地保留数据。

### 2.6.1　需要多少个broker

一个Kafka集群需要多少个broker取决于以下几个因素。
● 磁盘容量
● 单个broker的复制容量
● CPU
● 网络

目前，建议每个broker的分区副本不超过14 000个，每个集群的分区副本不超过100万个。

在大多数情况下，CPU通常不是主要瓶颈，但如果有很多客户端连接和请求，则CPU可能会成为瓶颈。

### 2.6.2　broker配置

要让一个broker加入集群，只需要修改两个配置参数。首先，所有broker都必须配置相同的zookeeper.connect，这个参数指定了用于保存元数据的ZooKeeper的群组和路径。其次，每个broker都必须为broker.id指定唯一的值。如果两个broker使用相同的broker.id，那么第二个broker将无法启动

### 2.6.3　操作系统调优

对大多数应用程序（特别是那些依赖吞吐量的应用程序）来说，要尽量避免内存交换。内存页和磁盘之间的数据交换对Kafka各方面的性能都有重大影响。Kafka大量使用了系统页面缓存，如果虚拟内存被交换到磁盘，则说明已经没有多余内存可以分配给页面缓存。

一种避免内存交换的方法是不设置任何交换分区。内存交换不是必需的，不过它确实能够在系统发生灾难性错误时提供一些帮助。内存交换可以防止操作系统由于内存不足而突然终止进程。基于上述原因，建议把vm.swappiness参数的值设置得小一些，比如设置为1。这个参数是指虚拟机子系统使用交换分区的权重百分比。要优先考虑减小页面缓存，而不是进行内存交换。

我们可以将vm.dirty_background_ratio设置为小于默认值10的数字。这个参数是指脏页占系统内存的百分比，大多数情况下设置为5就可以了。它不应该被设置为0，因为那样会促使内核频繁地刷新页面，从而降低内核为磁盘写入提供缓冲的能力。

如果要增加被内核进程刷新到磁盘之前的脏页数量，那么可以将vm.dirty_ratio设置为大于20的值（这个数值也是指脏页占系统内存的百分比）​。这个值可设置的范围很广，60~80是一个比较合理的区间。不过修改这个参数会带来一些风险，比如未刷新的磁盘操作的数量会增加，以及同步刷新导致的I/O等待时间会更长。如果将vm.dirty_ratio设置了较高的值，那么建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失。

一个broker如果有很多分区，那么它至少还需要 ( 分区数量 )×(分区大小 / 日志片段大小 ) 个文件描述符来跟踪所有的日志片段。因此，建议将vm.max_map_count设置为一个非常大的数字（基于前面的公式）​。根据环境的不同，将这个值设置为400 000或600 000是没有问题的。另外，建议将vm.overcommit_memory设置为0。0表示内核会根据应用程序来确定空闲内存的数量。如果这个参数被设置为0以外的值，则可能会导致操作系统夺走过多内存，从而减少Kafka的运行内存，这种情况在高摄取率的应用程序中很常见。

有很多种文件系统可供选择，对本地文件系统来说，Ext4（第四代扩展文件系统）和XFS（扩展文件系统）最为常见。XFS是很多Linux发行版默认的文件系统，因为它只需要做少量调优就可以承担大部分的工作负载，表现要优于Ext4。

XFS为Kafka提供了更好的性能，除了文件系统提供的自动调优，不需要再做额外的调优。另外，XFS的批量磁盘写入的效率更高，所有这些组合在一起，提高了整体的I/O吞吐量。

要合理设置挂载点的noatime属性。文件元数据包含3个时间戳：创建时间(ctime)、最后修改时间(mtime)和最后访问时间(atime)。在默认情况下，每次文件被读取后都会更新atime，这会导致大量的磁盘写操作。atime属性的用处并不大，除非应用程序想要知道某个文件在最近一次修改后有没有被访问过（对于这种情况可以使用relatime）​。Kafka没有用到atime这个属性，所以完全可以将其禁用。设置挂载点的noatime属性可以避免更新atime，但又不影响ctime和mtime。当有大量磁盘写入时，通过设置largeio也有助于提升Kafka的效率。

调整Kafka的网络配置与调整其他大部分Web服务器和网络应用程序的网络配置是一样的。首先，可以调整分配给socket读写缓冲区的默认内存和最大内存，这样可以显著提升大流量网络的传输性能。socket读写缓冲区内存对应的参数分别是net.core.wmem_default和net.core.rmem_default，合理的值是131 072（也就是128 KiB）​。读写缓冲区最大内存对应的参数分别是net.core.wmem_max和net.core.rmem_max，合理的值是2 097 152（也就是2 MiB）​。需要注意的是，最大值并不意味着每个socket一定要分配这么大的缓冲空间，只是在必要的情况下才会达到这个上限。

除了配置socket参数，还需要配置TCP socket的读写缓冲区，对应的参数分别是net.ipv4.tcp_wmem和net.ipv4.tcp_rmem。这些参数的值由3个整数组成，使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于net.core.wmem_max和net.core.rmem_max指定的大小。例如，​“4096 65536 2048000”表示最小值是4 KiB、默认值是64 KiB、最大值是2 MiB

## 2.7　生产环境的注意事项

### 2.7.1　垃圾回收器选项

建议将G1GC作为Kafka的默认垃圾回收器。在应用程序的整个生命周期中，G1GC会根据工作负载进行自我调节，并且停顿时间是恒定的。它可以轻松收集大块堆内存，把堆内存分为若干小块区域，并不是每次都回收整个堆空间。

MaxGCPauseMillis：该参数指定了每次垃圾回收的默认停顿时间。这个值不是固定的，G1GC可以根据具体情况进行调整，默认是200毫秒。G1GC可以决定垃圾回收的频率，以及每一轮需要回收多少个区域，这样算下来，每一轮垃圾回收大概需要200毫秒。

InitiatingHeapOccupancyPercent：该参数指定了在G1GC启动新一轮垃圾回收之前可以使用的堆内存百分比，默认是45。也就是说，在堆内存使用率达到45%之前，G1GC不会启动垃圾回收。这个百分比包括新生代和老年代的内存。

Kafka使用堆内存以及处理垃圾对象的效率是比较高的，所以可以把这些参数设置得小一些。如果一台服务器有64 GB内存，并使用5 GB堆内存来运行Kafka，那么可以将MaxGCPauseMillis设置为20毫秒，将InitiatingHeapOccupancyPercent设置为35，让垃圾回收比默认的早一些启动。Kafka是在G1GC之前发布的，因此，它默认使用的是CMS（并发标记和清除）垃圾回收器，以确保与所有的JVM兼容。

### 2.7.2　数据中心布局

Kafka可以将新创建的分区分配给部署在不同机架上的broker（机架感知）​，确保单个分区的副本不会都位于同一个机架。

总的来说，最好把集群的broker安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。也就是说，部署服务器需要至少两个电源连接（两个不同的回路）和两个网络交换器（保证可以进行无缝的故障切换）​。除了使用两个电源连接，最好把broker安装在不同的机架上。

### 2.7.3　共享ZooKeeper

Kafka使用ZooKeeper保存broker、主题和分区的元数据。只有当消费者群组成员或Kafka集群本身发生变化时才会向ZooKeeper写入数据。这些流量通常很小，所以没有必要为单个Kafka集群使用专门的ZooKeeper群组。实际上，有很多Kafka部署环境使用单个ZooKeeper群组来保存多个Kafka集群的元数据（正如本章之前所描述的那样，每个Kafka集群使用一个单独的chroot路径）​。

- Kafka 2.8.0（2021年）：首次引入 KRaft 模式（早期测试版，不推荐生产环境）。
- Kafka 3.0+（2022年）：KRaft 进入**生产就绪（Production-Ready）**阶段，但仍需谨慎评估。
- Kafka 3.3+（2023年）：进一步优化稳定性与性能，社区推荐新集群直接使用 KRaft。
- Kafka 3.5+（最新版本）：KRaft 已成为默认模式，ZooKeeper 模式逐步进入弃用流程。


# 第3章　Kafka生产者——向Kafka写入数据

多样的应用场景意味着多样的需求：是否每条消息都很重要？是否允许丢失一小部分消息？是否可以接受偶尔出现重复消息？是否有严格的延迟和吞吐量需求？不同的应用场景直接影响如何使用和配置生产者API。

先从创建一个ProducerRecord对象开始，其中需要包含目标主题和要发送的内容。另外，还可以指定键、分区、时间戳或标头。在发送ProducerRecord对象时，生产者需要先把键和值对象序列化成字节数组，这样才能在网络上传输。

接下来，如果没有显式地指定分区，那么数据将被传给分区器。分区器通常会基于ProducerRecord对象的键选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条消息了。紧接着，该消息会被添加到一个消息批次里，这个批次里的所有消息都将被发送给同一个主题和分区。有一个独立的线程负责把这些消息批次发送给目标broker。

broker在收到这些消息时会返回一个响应。如果消息写入成功，就返回一个RecordMetaData对象，其中包含了主题和分区信息，以及消息在分区中的偏移量。如果消息写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，重试几次之后如果还是失败，则会放弃重试，并返回错误信息。

## 3.2　创建Kafka生产者

Kafka生产者有3个必须设置的属性。

- key.serializer：broker的地址。可以由多个host:port组成，生产者用它们来建立初始的Kafka集群连接。它不需要包含所有的broker地址，因为生产者在建立初始连接之后可以从给定的broker那里找到其他broker的信息。不过还是建议至少提供两个broker地址，因为一旦其中一个停机，则生产者仍然可以连接到集群。

- key.serializer：一个类名，用来序列化消息的键。broker希望接收到的消息的键和值都是字节数组。生产者可以把任意Java对象作为键和值发送给broker，但它需要知道如何把这些Java对象转换成字节数组。key.serializer必须被设置为一个实现了org.apache.kafka.common.serialization.Serializer接口的类，生产者会用这个类把键序列化成字节数组。Kafka客户端默认提供了ByteArraySerializer、StringSerializer和IntegerSerializer等，如果你只使用常见的几种Java对象类型，就没有必要实现自己的序列化器。需要注意的是，必须设置key.serializer这个属性，尽管你可能只需要将值发送给Kafka。如果只需要发送值，则可以将Void作为键的类型，然后将这个属性设置为VoidSerializer。

- value.serializer：一个类名，用来序列化消息的值。与设置key.serializer属性一样，需要将value.serializer设置成可以序列化消息值对象的类。

```java
Properties kafkaProps = new Properties(); ➊
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer",
    "org.apache.kafka.common.serialization.StringSerializer"); ➋
kafkaProps.put("value.serializer",
    "org.apache.kafka.common.serialization.StringSerializer");

producer = new KafkaProducer<String, String>(kafkaProps); ➌
```

发送消息主要有以下3种方式。

- 发送并忘记：把消息发送给服务器，但并不关心它是否成功送达。大多数情况下，消息可以成功送达，因为Kafka是高可用的，而且生产者有自动尝试重发的机制。但是，如果发生了不可重试的错误或超时，那么消息将会丢失，应用程序将不会收到任何信息或异常。

- 同步发送：一般来说，生产者是异步的——我们调用send()方法发送消息，它会返回一个Future对象。可以调用get()方法等待Future完成，这样就可以在发送下一条消息之前知道当前消息是否发送成功。

- 异步发送：调用send()方法，并指定一个回调函数，当服务器返回响应时，这个函数会被触发。

```java
ProducerRecord<String, String> record =
    new ProducerRecord<>("CustomerCountry", "Precision Products",
        "France"); ➊
try {
    producer.send(record); ➋
} catch (Exception e) {
    e.printStackTrace(); ➌
}
```

```java
ProducerRecord<String, String> record =
    new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
    producer.send(record).get(); ➊
} catch (Exception e) {
    e.printStackTrace(); ➋
}
```

```java
private class DemoProducerCallback implements Callback { ➊
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if (e != null) {
            e.printStackTrace(); ➋
        }
    }
}

ProducerRecord<String, String> record =
    new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA"); ➌
producer.send(record, new DemoProducerCallback()); ➍
```

## 3.4　生产者配置

### 3.4.1　client.id

client.id是客户端标识符，它的值可以是任意字符串，broker用它来识别从客户端发送过来的消息。选择一个好的客户端标识符可以让故障诊断变得更容易些.

### 3.4.2　acks

acks指定了生产者在多少个分区副本收到消息的情况下才会认为消息写入成功。在默认情况下，Kafka会在首领副本收到消息后向客户端回应消息写入成功（Kafka 3.0预计会改变这个默认行为）​。这个参数对写入消息的持久性有重大影响，对于不同的场景，使用默认值可能不是最好的选择。

- acks=0: 如果acks=0，则生产者不会等待任何来自broker的响应。也就是说，如果broker因为某些问题没有收到消息，那么生产者便无从得知，消息也就丢失了。不过，因为生产者不需要等待broker返回响应，所以它们能够以网络可支持的最大速度发送消息，从而达到很高的吞吐量。

- acks=1: 如果acks=1，那么只要集群的首领副本收到消息，生产者就会收到消息成功写入的响应。如果消息无法到达首领副本（比如首领副本发生崩溃，新首领还未选举出来）​，那么生产者会收到一个错误响应。为了避免数据丢失，生产者会尝试重发消息。不过，在首领副本发生崩溃的情况下，如果消息还没有被复制到新的首领副本，则消息还是有可能丢失。

- acks=all: 如果acks=all，那么只有当所有副本全部收到消息时，生产者才会收到消息成功写入的响应。这种模式是最安全的，它可以保证不止一个broker收到消息，就算有个别broker发生崩溃，整个集群仍然可以运行（第6章将讨论更多的细节）​。不过，它的延迟比acks=1高，因为生产者需要等待不止一个broker确认收到消息。

### 3.4.3　消息传递时间

从Kafka 2.1开始，我们将ProduceRecord的发送时间分成如下两个时间间隔，它们是被分开处理的。

● 异步调用send()所花费的时间。在此期间，调用send()的线程将被阻塞。
● 从异步调用send()返回到触发回调（不管是成功还是失败）的时间，也就是从ProduceRecord被放到批次中直到Kafka成功响应、出现不可恢复异常或发送超时的时间。

- max.block.ms：这个参数用于控制在调用send()或通过partitionsFor()显式地请求元数据时生产者可以发生阻塞的时间。当生产者的发送缓冲区被填满或元数据不可用时，这些方法就可能发生阻塞。当达到max.block.ms配置的时间时，就会抛出一个超时异常。

- delivery.timeout.ms这个参数用于控制从消息准备好发送（send()方法成功返回并将消息放入批次中）到broker响应或客户端放弃发送（包括重试）所花费的时间。如图3-2所示，这个时间应该大于linger.ms和request.timeout.ms。如果配置的时间不满足这一点，则会抛出异常。通常，成功发送消息的速度要比delivery.timeout.ms快得多。一般建议这个时间大于broker重新选举的时间30s，建议可以配置为120。

- request.timeout.ms这个参数用于控制生产者在发送消息时等待服务器响应的时间。需要注意的是，这是指生产者在放弃之前等待每个请求的时间，不包括重试、发送之前所花费的时间等。如果设置的值已触及，但服务器没有响应，那么生产者将重试发送，或者执行回调，并传给它一个TimeoutException。

- retries 和retry.backoff.ms当生产者收到来自服务器的错误消息时，这个错误有可能是暂时的（例如，一个分区没有首领）​。在这种情况下，retries参数可用于控制生产者在放弃发送并向客户端宣告失败之前可以重试多少次。在默认情况下，重试时间间隔是100毫秒，但可以通过retry.backoff.ms参数来控制重试时间间隔。

生产者并不会重试所有的错误。有些错误不是暂时的，生产者就不会进行重试（例如，​“消息太大”错误）​。通常，对于可重试的错误，生产者会自动进行重试，所以不需要在应用程序中处理重试逻辑。你要做的是集中精力处理不可重试的错误或者当重试次数达到上限时的情况。

### 3.4.4　linger.ms

这个参数指定了生产者在发送消息批次之前等待更多消息加入批次的时间。生产者会在批次被填满或等待时间达到linger.ms时把消息批次发送出去。在默认情况下，只要有可用的发送者线程，生产者都会直接把批次发送出去，就算批次中只有一条消息。把linger.ms设置成比0大的数，可以让生产者在将批次发送给服务器之前等待一会儿，以使更多的消息加入批次中。虽然这样会增加一点儿延迟，但也极大地提升了吞吐量。这是因为一次性发送的消息越多，每条消息的开销就越小，如果启用了压缩，则计算量也更少了。

### 3.4.5　buffer.memory

这个参数用来设置生产者要发送给服务器的消息的内存缓冲区大小。如果应用程序调用send()方法的速度超过生产者将消息发送给服务器的速度，那么生产者的缓冲空间可能会被耗尽，后续的send()方法调用会等待内存空间被释放，如果在max.block.ms之后还没有可用空间，就抛出异常。需要注意的是，这个异常与其他异常不一样，它是send()方法而不是Future对象抛出来的。

### 3.4.6　compression.type

在默认情况下，生产者发送的消息是未经压缩的。这个参数可以被设置为snappy、gzip、lz4或zstd，这指定了消息被发送给broker之前使用哪一种压缩算法。snappy压缩算法由谷歌发明，虽然占用较少的CPU时间，但能提供较好的性能和相当可观的压缩比。如果同时有性能和网络带宽方面的考虑，那么可以使用这种算法。gzip压缩算法通常会占用较多的CPU时间，但提供了更高的压缩比。如果网络带宽比较有限，则可以使用这种算法。使用压缩可以降低网络传输和存储开销，而这些往往是向Kafka发送消息的瓶颈所在。

### 3.4.7　batch.size

当有多条消息被发送给同一个分区时，生产者会把它们放在同一个批次里。这个参数指定了一个批次可以使用的内存大小。需要注意的是，该参数是按照字节数而不是消息条数来计算的。当批次被填满时，批次里所有的消息都将被发送出去。但是生产者并不一定都会等到批次被填满时才将其发送出去。那些未填满的批次，甚至只包含一条消息的批次也有可能被发送出去。所以，就算把批次大小设置得很大，也不会导致延迟，只是会占用更多的内存而已。但如果把批次大小设置得太小，则会增加一些额外的开销，因为生产者需要更频繁地发送消息。

### 3.4.8　max.in.flight.requests.per.connection

这个参数指定了生产者在收到服务器响应之前可以发送多少个消息批次。它的值越大，占用的内存就越多，不过吞吐量也会得到提升。在单数据中心环境中，该参数被设置为2时可以获得最佳的吞吐量，但使用默认值5也可以获得差不多的性能。

Kafka可以保证同一个分区中的消息是有序的。也就是说，如果生产者按照一定的顺序发送消息，那么broker会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们。在某些情况下，顺序是非常重要的。

### 3.4.9　max.request.size

这个参数用于控制生产者发送的请求的大小。它限制了可发送的单条最大消息的大小和单个请求的消息总量的大小。另外，broker对可接收的最大消息也有限制(message.max.bytes)，其两边的配置最好是匹配的，以免生产者发送的消息被broker拒绝。

### 3.4.10　receive.buffer.bytes和send.buffer.bytes

这两个参数分别指定了TCP socket接收和发送数据包的缓冲区大小。如果它们被设为–1，就使用操作系统默认值。如果生产者或消费者与broker位于不同的数据中心，则可以适当加大它们的值，因为跨数据中心网络的延迟一般都比较高，而带宽又比较低。

### 3.4.11　enable.idempotence

为了避免broker出现重复的消息，可以将enable.idempotence设置为true。当幂等生产者被启用时，生产者将给发送的每一条消息都加上一个序列号。如果broker收到具有相同序列号的消息，那么它就会拒绝第二个副本，而生产者则会收到DuplicateSequenceException，这个异常对生产者来说是无害的。

如果要启用幂等性，那么max.in.flight.requests.per.connection应小于或等于5、retries应大于0，并且acks被设置为all。如果设置了不恰当的值，则会抛出ConfigException异常。



