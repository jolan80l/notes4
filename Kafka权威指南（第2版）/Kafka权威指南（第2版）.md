1. 初识Kafka

## 1.1　发布与订阅消息系统

数据（消息）的发送者（发布者）不会直接把消息发送给接收者，这是发布与订阅消息系统的一个特点。发布者以某种方式对消息进行分类，接收者（订阅者）通过订阅它们来接收特定类型的消息。发布与订阅系统一般会有一个broker，也就是发布消息的地方。

真正需要的是一个单一的集中式系统，它可以用来发布通用的数据，并且规模可以随着公司业务的增长而增长。

## 1.2　Kafka登场

Kafka就是为了解决上述问题而设计的一款基于发布与订阅模式的消息系统。

### 1.2.1　消息和批次

Kafka的数据单元被称为消息。消息可以有一个可选的元数据，也就是键。当需要以一种可控的方式将消息写入不同的分区时，需要用到键。最简单的例子就是为键生成一个一致性哈希值，然后用哈希值对主题分区数进行取模，为消息选取分区。这样可以保证具有相同键的消息总是会被写到相同的分区中（前提是分区数量没有发生变化）​。

为了提高效率，消息会被分成批次写入Kafka。批次包含了一组属于同一个主题和分区的消息。如果每一条消息都单独穿行于网络中，那么就会导致大量的网络开销，把消息分成批次传输可以减少网络开销。不过，这需要在时间延迟和吞吐量之间做出权衡：批次越大，单位时间内处理的消息就越多，对单条消息来说，其传输时间就越长。消息批次会被压缩，这样可以提升数据的传输和存储性能，但需要做更多的计算处理。

### 1.2.2　模式

### 1.2.3　主题和分区

Kafka的消息通过主题进行分类。主题就好比数据库的表或文件系统的文件夹。主题可以被分为若干个分区，一个分区就是一个提交日志。

需要注意的是，由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内是有序的。

![avatar](img/1.png)

生产者创建消息。在其他发布与订阅系统中，生产者可能被称为发布者或写入者。一条消息会被发布到一个特定的主题上。在默认情况下，生产者会把消息均衡地分布到主题的所有分区中。不过，在某些情况下，生产者会把消息直接写入指定的分区，这通常是通过消息键和分区器来实现的。分区器会为键生成一个哈希值，并将其映射到指定的分区，这样可以保证包含同一个键的消息被写入同一个分区。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到不同的分区。

消费者读取消息。在其他发布与订阅系统中，消费者可能被称为订阅者或读取者。消费者会订阅一个或多个主题，并按照消息写入分区的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量（不断递增的整数值）是另一种元数据，在创建消息时，Kafka会把它添加到消息里。在给定的分区中，每一条消息的偏移量都是唯一的，越往后消息的偏移量越大（但不一定是严格单调递增）​。消费者会把每一个分区可能的下一个偏移量保存起来（通常保存在Kafka中）​，如果消费者关闭或重启，则其读取状态不会丢失。

消费者可以是消费者群组的一部分，属于同一群组的一个或多个消费者共同读取一个主题。群组可以保证每个分区只被这个群组里的一个消费者读取

消费者与分区之间的映射通常被称为消费者对分区的所有权关系。

通过这种方式，消费者可以读取包含大量消息的主题。而且，如果一个消费者失效，那么群组里的其他消费者可以接管失效消费者的工作。

### 1.2.5　broker和集群

一台单独的Kafka服务器被称为broker。broker会接收来自生产者的消息，为其设置偏移量，并提交到磁盘保存。broker会为消费者提供服务，对读取分区的请求做出响应，并返回已经发布的消息。

broker组成了集群。每个集群都有一个同时充当了集群控制器角色的broker（自动从活动的集群成员中选举出来）​。控制器负责管理工作，包括为broker分配分区和监控broker。在集群中，一个分区从属于一个broker，这个broker被称为分区的首领。一个被分配给其他broker的分区副本（参见图1-7）叫作这个分区的“跟随者”​。分区复制提供了分区的消息冗余，如果一个broker发生故障，则其中的一个跟随者可以接管它的领导权。所有想要发布消息的生产者必须连接到首领，但消费者可以从首领或者跟随者那里读取消息。第7章将详细介绍如何操作集群（包括复制分区）​。

保留消息（在一定期限内）是Kafka的一个重要特性。broker默认的消息保留策略是这样的：要么保留一段时间（如7天）​，要么保留消息总量达到一定的字节数（如1 GB）​。当消息数量达到这些上限时，旧消息就会过期并被删除。

### 1.2.6　多集群

随着broker数量的增加，最好使用多个集群，原因如下。
● 数据类型分离
● 安全需求隔离
● 多数据中心（灾难恢复）

需要注意的是，Kafka的消息复制机制只能在单个集群中而不能在多个集群之间进行。

## 1.3　为什么选择Kafka

### 1.3.1　多个生产者

Kafka可以无缝支持多个生产者，不管客户端消费的是单个主题还是多个主题。所以，它很适用于从多个前端系统收集数据，并以统一的格式对外提供数据。

### 1.3.2　多个消费者

除了支持多个生产者，Kafka也支持多个消费者从一个单独的消息流读取数据，而且消费者之间互不影响。这与其他队列系统不同。在其他队列系统中，消息一旦被一个客户端读取，就无法再被其他客户端读取。多个消费者还可以组成一个群组，它们共享一个消息流，并保证整个群组只处理一次给定的消息。

### 1.3.3　基于磁盘的数据保留

Kafka不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于Kafka的数据保留特性。消息会被提交到磁盘，并根据设置的保留策略进行保存。每个主题可以设置单独的保留策略，以满足不同消费者的需求。各个主题还可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰而无法及时读取消息，在这种情况下，持久化的数据可以保证数据不会丢失

### 1.3.4　伸缩性

为了能够轻松地处理大量数据，Kafka从一开始就被设计成一个具备灵活伸缩性的系统。用户可以在开发阶段使用单个broker，然后再扩展到包含3个broker的小型开发集群。随着数据量不断增长，在部署到生产环境时，集群可以包含上百个broker。对在线集群进行扩展丝毫不影响系统的整体可用性。也就是说，一个包含多个broker的集群，即使个别broker失效，仍然可以持续地为客户端提供服务

### 1.3.5　高性能

### 1.3.6　平台特性

Kafka核心项目还加入了一些流式平台特性，从而使开发人员能够更容易执行一些常见的任务。结构化运行时环境）​，但这些特性会以API和开。

### 1.4　数据生态系统

应用场景：

- 活动跟踪
- 传递消息
- 指标和日志记录
- 提交日志
- 流式处理

# 第2章　安装Kafka

## 2.1　环境配置

### 2.1.1　选择操作系统

### 2.1.2　安装Java

在安装ZooKeeper或Kafka之前，需要有一个Java运行时环境。Kafka和ZooKeeper可以运行在所有基于OpenJDK的Java运行时中，包括OracleJDK。

### 2.1.3　安装ZooKeeper

为了保证高可用，ZooKeeper以集群（被称为群组）的方式运行。由于使用了再均衡算法，建议一个ZooKeeper集群应该包含奇数个节点（比如3个、5个等）​。只有当群组中的大多数节点（也就是所谓的仲裁）处于可用状态时，ZooKeeper才能处理外部请求。也就是说，一个包含3个节点的群组允许1个节点失效，而一个包含5个节点的群组允许2个节点失效。

## 2.2　安装broker

根据时间保留数据是通过检查日志片段文件的最后修改时间来实现的。一般来说，最后修改时间就是日志片段的关闭时间，也就是文件中最后一条消息的时间戳。不过，如果使用管理工具在服务器间移动分区，那么最后修改时间就不准确了，这种误差可能会导致这些分区过多地保留数据。

### 2.6.1　需要多少个broker

一个Kafka集群需要多少个broker取决于以下几个因素。
● 磁盘容量
● 单个broker的复制容量
● CPU
● 网络

目前，建议每个broker的分区副本不超过14 000个，每个集群的分区副本不超过100万个。

在大多数情况下，CPU通常不是主要瓶颈，但如果有很多客户端连接和请求，则CPU可能会成为瓶颈。

### 2.6.2　broker配置

要让一个broker加入集群，只需要修改两个配置参数。首先，所有broker都必须配置相同的zookeeper.connect，这个参数指定了用于保存元数据的ZooKeeper的群组和路径。其次，每个broker都必须为broker.id指定唯一的值。如果两个broker使用相同的broker.id，那么第二个broker将无法启动

### 2.6.3　操作系统调优

对大多数应用程序（特别是那些依赖吞吐量的应用程序）来说，要尽量避免内存交换。内存页和磁盘之间的数据交换对Kafka各方面的性能都有重大影响。Kafka大量使用了系统页面缓存，如果虚拟内存被交换到磁盘，则说明已经没有多余内存可以分配给页面缓存。

一种避免内存交换的方法是不设置任何交换分区。内存交换不是必需的，不过它确实能够在系统发生灾难性错误时提供一些帮助。内存交换可以防止操作系统由于内存不足而突然终止进程。基于上述原因，建议把vm.swappiness参数的值设置得小一些，比如设置为1。这个参数是指虚拟机子系统使用交换分区的权重百分比。要优先考虑减小页面缓存，而不是进行内存交换。

我们可以将vm.dirty_background_ratio设置为小于默认值10的数字。这个参数是指脏页占系统内存的百分比，大多数情况下设置为5就可以了。它不应该被设置为0，因为那样会促使内核频繁地刷新页面，从而降低内核为磁盘写入提供缓冲的能力。

如果要增加被内核进程刷新到磁盘之前的脏页数量，那么可以将vm.dirty_ratio设置为大于20的值（这个数值也是指脏页占系统内存的百分比）​。这个值可设置的范围很广，60~80是一个比较合理的区间。不过修改这个参数会带来一些风险，比如未刷新的磁盘操作的数量会增加，以及同步刷新导致的I/O等待时间会更长。如果将vm.dirty_ratio设置了较高的值，那么建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失。

一个broker如果有很多分区，那么它至少还需要 ( 分区数量 )×(分区大小 / 日志片段大小 ) 个文件描述符来跟踪所有的日志片段。因此，建议将vm.max_map_count设置为一个非常大的数字（基于前面的公式）​。根据环境的不同，将这个值设置为400 000或600 000是没有问题的。另外，建议将vm.overcommit_memory设置为0。0表示内核会根据应用程序来确定空闲内存的数量。如果这个参数被设置为0以外的值，则可能会导致操作系统夺走过多内存，从而减少Kafka的运行内存，这种情况在高摄取率的应用程序中很常见。

有很多种文件系统可供选择，对本地文件系统来说，Ext4（第四代扩展文件系统）和XFS（扩展文件系统）最为常见。XFS是很多Linux发行版默认的文件系统，因为它只需要做少量调优就可以承担大部分的工作负载，表现要优于Ext4。

XFS为Kafka提供了更好的性能，除了文件系统提供的自动调优，不需要再做额外的调优。另外，XFS的批量磁盘写入的效率更高，所有这些组合在一起，提高了整体的I/O吞吐量。

要合理设置挂载点的noatime属性。文件元数据包含3个时间戳：创建时间(ctime)、最后修改时间(mtime)和最后访问时间(atime)。在默认情况下，每次文件被读取后都会更新atime，这会导致大量的磁盘写操作。atime属性的用处并不大，除非应用程序想要知道某个文件在最近一次修改后有没有被访问过（对于这种情况可以使用relatime）​。Kafka没有用到atime这个属性，所以完全可以将其禁用。设置挂载点的noatime属性可以避免更新atime，但又不影响ctime和mtime。当有大量磁盘写入时，通过设置largeio也有助于提升Kafka的效率。

调整Kafka的网络配置与调整其他大部分Web服务器和网络应用程序的网络配置是一样的。首先，可以调整分配给socket读写缓冲区的默认内存和最大内存，这样可以显著提升大流量网络的传输性能。socket读写缓冲区内存对应的参数分别是net.core.wmem_default和net.core.rmem_default，合理的值是131 072（也就是128 KiB）​。读写缓冲区最大内存对应的参数分别是net.core.wmem_max和net.core.rmem_max，合理的值是2 097 152（也就是2 MiB）​。需要注意的是，最大值并不意味着每个socket一定要分配这么大的缓冲空间，只是在必要的情况下才会达到这个上限。

除了配置socket参数，还需要配置TCP socket的读写缓冲区，对应的参数分别是net.ipv4.tcp_wmem和net.ipv4.tcp_rmem。这些参数的值由3个整数组成，使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于net.core.wmem_max和net.core.rmem_max指定的大小。例如，​“4096 65536 2048000”表示最小值是4 KiB、默认值是64 KiB、最大值是2 MiB

## 2.7　生产环境的注意事项

### 2.7.1　垃圾回收器选项

建议将G1GC作为Kafka的默认垃圾回收器。在应用程序的整个生命周期中，G1GC会根据工作负载进行自我调节，并且停顿时间是恒定的。它可以轻松收集大块堆内存，把堆内存分为若干小块区域，并不是每次都回收整个堆空间。

MaxGCPauseMillis：该参数指定了每次垃圾回收的默认停顿时间。这个值不是固定的，G1GC可以根据具体情况进行调整，默认是200毫秒。G1GC可以决定垃圾回收的频率，以及每一轮需要回收多少个区域，这样算下来，每一轮垃圾回收大概需要200毫秒。

InitiatingHeapOccupancyPercent：该参数指定了在G1GC启动新一轮垃圾回收之前可以使用的堆内存百分比，默认是45。也就是说，在堆内存使用率达到45%之前，G1GC不会启动垃圾回收。这个百分比包括新生代和老年代的内存。

Kafka使用堆内存以及处理垃圾对象的效率是比较高的，所以可以把这些参数设置得小一些。如果一台服务器有64 GB内存，并使用5 GB堆内存来运行Kafka，那么可以将MaxGCPauseMillis设置为20毫秒，将InitiatingHeapOccupancyPercent设置为35，让垃圾回收比默认的早一些启动。Kafka是在G1GC之前发布的，因此，它默认使用的是CMS（并发标记和清除）垃圾回收器，以确保与所有的JVM兼容。

### 2.7.2　数据中心布局

Kafka可以将新创建的分区分配给部署在不同机架上的broker（机架感知）​，确保单个分区的副本不会都位于同一个机架。

总的来说，最好把集群的broker安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。也就是说，部署服务器需要至少两个电源连接（两个不同的回路）和两个网络交换器（保证可以进行无缝的故障切换）​。除了使用两个电源连接，最好把broker安装在不同的机架上。

### 2.7.3　共享ZooKeeper

Kafka使用ZooKeeper保存broker、主题和分区的元数据。只有当消费者群组成员或Kafka集群本身发生变化时才会向ZooKeeper写入数据。这些流量通常很小，所以没有必要为单个Kafka集群使用专门的ZooKeeper群组。实际上，有很多Kafka部署环境使用单个ZooKeeper群组来保存多个Kafka集群的元数据（正如本章之前所描述的那样，每个Kafka集群使用一个单独的chroot路径）​。

- Kafka 2.8.0（2021年）：首次引入 KRaft 模式（早期测试版，不推荐生产环境）。
- Kafka 3.0+（2022年）：KRaft 进入**生产就绪（Production-Ready）**阶段，但仍需谨慎评估。
- Kafka 3.3+（2023年）：进一步优化稳定性与性能，社区推荐新集群直接使用 KRaft。
- Kafka 3.5+（最新版本）：KRaft 已成为默认模式，ZooKeeper 模式逐步进入弃用流程。


# 第3章　Kafka生产者——向Kafka写入数据

多样的应用场景意味着多样的需求：是否每条消息都很重要？是否允许丢失一小部分消息？是否可以接受偶尔出现重复消息？是否有严格的延迟和吞吐量需求？

